{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing... This will take 1 minute...\n",
      "Looking in indexes: https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/\n",
      "Requirement already satisfied: ort-nightly-gpu in /usr/local/lib/python3.8/site-packages (1.17.0.dev20240118002)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/site-packages (from ort-nightly-gpu) (24.3.7)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/site-packages (from ort-nightly-gpu) (4.25.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from ort-nightly-gpu) (23.2)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/site-packages (from ort-nightly-gpu) (1.23.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/site-packages (from ort-nightly-gpu) (1.12)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.8/site-packages (from ort-nightly-gpu) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.8/site-packages (from coloredlogs->ort-nightly-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/site-packages (from sympy->ort-nightly-gpu) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Installation done !\n"
     ]
    }
   ],
   "source": [
    "#@markdown #Installation\n",
    "#@markdown *Run this cell to install MVSep-MDX23*\n",
    "print('Installing... This will take 1 minute...')\n",
    "#%cd /content\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content')\n",
    "\n",
    "!git clone https://github.com/jarredou/MVSEP-MDX23-Colab_v2.git &> /dev/null\n",
    "\n",
    "os.chdir('/content/MVSEP-MDX23-Colab_v2')\n",
    "\n",
    "!pip install -r requirements.txt &> /dev/null\n",
    "# onnxruntime-gpu nightly fix for cuda12.2\n",
    "!python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/\n",
    "print('Installation done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU use: 0\n",
      "started!\n",
      "\n",
      "Options: \n",
      "BigShifts: 7\n",
      "\n",
      "weight_InstVoc: 8.0\n",
      "weight_VitLarge: 5.0\n",
      "\n",
      "overlap_InstVoc: 1\n",
      "overlap_VitLarge: 1\n",
      "\n",
      "use_VOCFT: False\n",
      "vocals_only: True\n",
      "output_format: PCM_16\n",
      "\n",
      "Loading InstVoc into memory\n",
      "100%|████████████████████████████████████████| 427M/427M [00:54<00:00, 8.26MB/s]\n",
      "100%|███████████████████████████████████████████| 709/709 [00:00<00:00, 811kB/s]\n",
      "Loading VitLarge into memory\n",
      "100%|████████████████████████████████████████| 824M/824M [01:36<00:00, 8.91MB/s]\n",
      "100%|██████████████████████████████████████| 1.21k/1.21k [00:00<00:00, 12.6kB/s]\n",
      "Downloading model.safetensors: 100%|█████████| 850M/850M [01:22<00:00, 10.4MB/s]\n",
      "Go for: /content/dataset/Huh_Ori_HP-KAROKEE-MSB2-3BAND-3090_arch-124m_Vocals_converted.wav\n",
      "Input audio: (2, 13159152) Sample rate: 44100\n",
      "Processing vocals with VitLarge model...\n",
      " 57%|█████████████████████████▋                   | 4/7 [00:36<00:33, 11.03s/it]^C\n"
     ]
    }
   ],
   "source": [
    "#@markdown #Separation\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "os.chdir('/content/MVSEP-MDX23-Colab_v2')\n",
    "\n",
    "input = '/content/dataset' #@param {type:\"string\"}\n",
    "output_folder = '/content/output' #@param {type:\"string\"}\n",
    "#@markdown ---\n",
    "#@markdown *Bigshifts=1 to disable that feature*\n",
    "\n",
    "BigShifts = 7 #@param {type:\"slider\", min:1, max:41, step:1}\n",
    "#@markdown ---\n",
    "overlap_InstVoc = 1 #@param {type:\"slider\", min:1, max:40, step:1}\n",
    "overlap_VitLarge = 1 #@param {type:\"slider\", min:1, max:40, step:1}\n",
    "#@markdown ---\n",
    "weight_InstVoc = 8 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "weight_VitLarge = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown ---\n",
    "use_VOCFT = False #@param {type:\"boolean\"}\n",
    "overlap_VOCFT = 0.1 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
    "weight_VOCFT = 2 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "#@markdown ---\n",
    "vocals_instru_only = True #@param {type:\"boolean\"}\n",
    "overlap_demucs = 0.6 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
    "#@markdown ---\n",
    "output_format = 'PCM_16' #@param [\"PCM_16\", \"FLOAT\"]\n",
    "if vocals_instru_only:\n",
    "    vocals_only = '--vocals_only true'\n",
    "else:\n",
    "    vocals_only = ''\n",
    "\n",
    "\n",
    "if use_VOCFT:\n",
    "    use_VOCFT = '--use_VOCFT true'\n",
    "else:\n",
    "    use_VOCFT = ''\n",
    "\n",
    "if Path(input).is_file():\n",
    "  file_path = input\n",
    "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "  !python inference.py \\\n",
    "        --large_gpu \\\n",
    "        --weight_InstVoc {weight_InstVoc} \\\n",
    "        --weight_VOCFT {weight_VOCFT} \\\n",
    "        --weight_VitLarge {weight_VitLarge} \\\n",
    "        --input_audio \"{file_path}\" \\\n",
    "        --overlap_demucs {overlap_demucs} \\\n",
    "        --overlap_VOCFT {overlap_VOCFT} \\\n",
    "        --overlap_InstVoc {overlap_InstVoc} \\\n",
    "        --overlap_VitLarge {overlap_VitLarge} \\\n",
    "        --output_format {output_format} \\\n",
    "        --BigShifts {BigShifts} \\\n",
    "        --output_folder \"{output_folder}\" \\\n",
    "        {vocals_only} \\\n",
    "        {use_VOCFT}\n",
    "\n",
    "else:\n",
    "  file_paths = sorted([f'\"{glob.escape(path)}\"' for path in glob.glob(input + \"/*\")])[:]\n",
    "  input_audio_args = ' '.join(file_paths)\n",
    "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "  !python inference.py \\\n",
    "          --large_gpu \\\n",
    "          --weight_InstVoc {weight_InstVoc} \\\n",
    "          --weight_VOCFT {weight_VOCFT} \\\n",
    "          --weight_VitLarge {weight_VitLarge} \\\n",
    "          --input_audio {input_audio_args} \\\n",
    "          --overlap_demucs {overlap_demucs} \\\n",
    "          --overlap_VOCFT {overlap_VOCFT} \\\n",
    "          --overlap_InstVoc {int(overlap_InstVoc)} \\\n",
    "          --overlap_VitLarge {int(overlap_VitLarge)} \\\n",
    "          --output_format {output_format} \\\n",
    "          --BigShifts {BigShifts} \\\n",
    "          --output_folder \"{output_folder}\" \\\n",
    "          {vocals_only} \\\n",
    "          {use_VOCFT}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset (Isolate Vocals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ### Input files\n",
    "#@markdown Track name / any link (Upload your songs in tracks folder)\n",
    "input = \"https://www.youtube.com/watch?v=nSzwuS-mvkk&t=90s\" #@param {type:\"string\"}\n",
    "input = 'https://www.youtube.com/watch?v=6RQ-bBdASvk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content')\n",
    "# ------------VSC REWRITE\n",
    "# pyright: reportMissingImports=false, reportUnusedVariable=warning, reportUntypedBaseClass=error\n",
    "from IPython.display import Audio, display\n",
    "#from google.colab import output\n",
    "#from google.colab import drive\n",
    "#from google.colab import files\n",
    "from sys import exit\n",
    "import zipfile\n",
    "import hashlib\n",
    "import os.path\n",
    "import shutil\n",
    "import psutil\n",
    "import random\n",
    "import glob\n",
    "import time\n",
    "import zlib\n",
    "import sys\n",
    "import torch \n",
    "from pathvalidate import sanitize_filename # for inference cell\n",
    "import yt_dlp as youtube_dl # for inference cell\n",
    "\n",
    "isCPU = torch.cuda.is_available()\n",
    "#@markdown Uncheck if you want to use VocalRemover5 without mounting to drive.\n",
    "MountDrive = False #@param{type:\"boolean\"}\n",
    "#@markdown Use mounting method\n",
    "method = 'new' #@param [\"new\",\"old\"]\n",
    "#@markdown Mounting path; don't touch this if you don't know what you're doing\n",
    "mounting_path = '/content/drive/MyDrive' #@param [\"snippets:\",\"/content/drive/MyDrive\",\"/content/drive/Shareddrives/<your shared drive name>\", \"/content/drive/Shareddrives/Shared Drive\"]{allow-input: true}\n",
    "#@markdown Force trigger update\n",
    "ForceUpdate = False #@param{type:\"boolean\"}\n",
    "\n",
    "#update channels\n",
    "ai = 'https://github.com/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover'\n",
    "vercheck = 'https://raw.githubusercontent.com/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/main/v'\n",
    "model_ver = 'https://raw.githubusercontent.com/NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover/main/model_list'\n",
    "\n",
    "class hide_opt: # hide outputs\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "def get_size(bytes, suffix='B'): # read ram\n",
    "    global svmem\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f'{bytes:.2f}{unit}{suffix}'\n",
    "        bytes /= factor\n",
    "    svmem = psutil.virtual_memory()\n",
    "\n",
    "def validateModelLinks():\n",
    "    with hide_opt():\n",
    "        get_ipython().system('wget {} -O model_ver'.format(model_ver))\n",
    "    model_ver_ = open(\"model_ver\", \"r\")\n",
    "    model_ver_ = model_ver_.read()\n",
    "    with hide_opt():\n",
    "        get_ipython().system('wget {} -O model_list'.format(model_ver_))\n",
    "    model_list = open(\"model_list\", \"r\")\n",
    "    model_list = model_list.readlines()\n",
    "    models = []\n",
    "    for i in model_list:\n",
    "        models.append(i)\n",
    "    os.remove('model_ver')\n",
    "    os.remove('model_list')\n",
    "    return models\n",
    "\n",
    "def installAI():\n",
    "    print('Installing ai...', end=' ')\n",
    "    get_ipython().system('git clone {} VocalRemover5-COLAB_arch'.format(ai))\n",
    "    os.chdir('VocalRemover5-COLAB_arch')\n",
    "    print('done')\n",
    "\n",
    "    print('Downloading models...', end=' ')\n",
    "    for i in validateModelLinks():\n",
    "        with hide_opt():\n",
    "            zname = sanitize_filename(os.path.basename(i))\n",
    "            get_ipython().system(\"wget {}\".format(i))\n",
    "            get_ipython().system('unzip -o {}'.format(zname))\n",
    "            os.remove(zname)\n",
    "    print('done')\n",
    "\n",
    "def dlvr(): # download vr to colab only\n",
    "    print('Warning: changes will not be saved.')\n",
    "    print('Downloading VR5...')\n",
    "\n",
    "    os.chdir('/content')\n",
    "    installAI()\n",
    "    #os.chdir('/content/VocalRemover5-COLAB_arch')\n",
    "    print (\"Success!\")\n",
    "\n",
    "def check_update():\n",
    "    if os.path.isdir(f'{mounting_path}/VocalRemover5-COLAB_arch'): # check update if ai installed is True\n",
    "        os.chdir(f'{mounting_path}/VocalRemover5-COLAB_arch')\n",
    "        print(\"Checking for updates...\", end=\" \")\n",
    "        with hide_opt():\n",
    "            get_ipython().system('wget {} -O check_ver'.format(vercheck))\n",
    "        f = open(\"check_ver\", \"r\")\n",
    "        nver = f.read()\n",
    "        f = open(\"v\", \"r\")\n",
    "        cver = f.read()\n",
    "        if cver != nver or ForceUpdate:\n",
    "            print('New update found! {}'.format(nver))\n",
    "            choice = str(input('Do you want to update? y/n')).lower()\n",
    "            if choice == 'y':\n",
    "                os.chdir('../')\n",
    "                print('Updating ai...',end=' ')\n",
    "                with hide_opt():\n",
    "                    get_ipython().system('git clone {} temp_VocalRemover5-COLAB_arch'.format(ai))\n",
    "                get_ipython().system('cp -a temp_VocalRemover5-COLAB_arch/* VocalRemover5-COLAB_arch/')\n",
    "                get_ipython().system('rm -rf temp_VocalRemover5-COLAB_arch')\n",
    "                print('done')\n",
    "\n",
    "                print('Downloading models...', end=' ')\n",
    "                os.chdir('VocalRemover5-COLAB_arch')\n",
    "                for i in validateModelLinks():\n",
    "                    with hide_opt():\n",
    "                        zname = sanitize_filename(os.path.basename(i))\n",
    "                        get_ipython().system(\"wget {}\".format(i))\n",
    "                        get_ipython().system('unzip -o {}'.format(zname))\n",
    "                        os.remove(zname)\n",
    "                print('done')\n",
    "                output.clear()\n",
    "                os.remove(f'{mounting_path}/VocalRemover5-COLAB_arch/v')\n",
    "                os.rename(f'{mounting_path}/VocalRemover5-COLAB_arch/check_ver',f'{mounting_path}/VocalRemover5-COLAB_arch/v')\n",
    "                os.chdir(f'{mounting_path}/VocalRemover5-COLAB_arch') # just to make sure\n",
    "\n",
    "            else:\n",
    "                print('Skipping update.')\n",
    "                os.remove(f'{mounting_path}/VocalRemover5-COLAB_arch/v')\n",
    "                os.rename(f'{mounting_path}/VocalRemover5-COLAB_arch/check_ver',f'{mounting_path}/VocalRemover5-COLAB_arch/v')\n",
    "                os.chdir(f'{mounting_path}/VocalRemover5-COLAB_arch') # just to make sure\n",
    "        else:\n",
    "            os.remove('check_ver')\n",
    "            print('No update found.')\n",
    "    else:\n",
    "            if os.path.isdir('/content/VocalRemover5-COLAB_arch'):\n",
    "                print(\"Success!\")\n",
    "            else:\n",
    "                dlvr()\n",
    "\n",
    "#-------------Script begin-------------\n",
    "if os.path.isdir('/content/VocalRemover5-COLAB_arch') == False:\n",
    "    if os.path.isdir('/content/VocalRemover5-COLAB_arch'):\n",
    "        print('Success!')\n",
    "    else:\n",
    "        dlvr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----------DEFINE INFERENCE REQ------------\n",
    "def crc32(fileName):\n",
    "    with open(fileName, 'rb') as fh:\n",
    "        hash = 0\n",
    "        while True:\n",
    "            s = fh.read(65536)\n",
    "            if not s:\n",
    "                break\n",
    "            hash = zlib.crc32(s, hash)\n",
    "        return \"%08X\" % (hash & 0xFFFFFFFF)\n",
    "def YouTube(link, dl=True):\n",
    "    inputsha = hashlib.sha1(bytes(link, encoding='utf8')).hexdigest() + '.wav'\n",
    "    fmt = '251/140/250/139'\n",
    "    opt = {'format': fmt, 'outtmpl': inputsha, 'updatetime': False, 'nocheckcertificate': True}\n",
    "    if dl == True:\n",
    "        print('YouTube link detected')\n",
    "        print('Downloading...', end=' ')\n",
    "    with hide_opt():\n",
    "        with youtube_dl.YoutubeDL(opt) as ydl:\n",
    "            global desc\n",
    "            if dl == True:\n",
    "                desc = ydl.extract_info(link, download=not os.path.isfile(inputsha))\n",
    "            else:\n",
    "                desc = ydl.extract_info(link, download=not True)\n",
    "\n",
    "    titlename = sanitize_filename(desc['title'])\n",
    "    if dl == True:\n",
    "        print('done')\n",
    "        print(titlename)\n",
    "    if dl == True:\n",
    "        return titlename, inputsha\n",
    "    else:\n",
    "        return titlename\n",
    "def zipdir(folder, zipname): # LINUX CALL MODIFIED!!!\n",
    "    if '.zip' in zipname:\n",
    "        zipname = zipname.strip('.zip')\n",
    "    get_ipython().system('zip -r {}.zip {}'.format(zipname,folder))\n",
    "# dlFile(input,pretrained_model,isYouTube='http://' in input,export_as_mp3=export_as_mp3)\n",
    "def dlFile(track,pretrained_model,isYouTube=False,export_as_mp3=False):\n",
    "    modelname = os.path.splitext(os.path.basename(pretrained_model))[0]\n",
    "    stems = [f'_{modelname}_Instruments',f'_{modelname}_Vocals']\n",
    "    filename = os.path.splitext(os.path.basename(track))[0]\n",
    "    if isYouTube:\n",
    "        filename = YouTube(track,dl=False)\n",
    "    if os.path.isdir(filename):\n",
    "        shutil.rmtree(filename)\n",
    "        os.mkdir(filename)\n",
    "    else:\n",
    "        os.mkdir(filename)\n",
    "    if os.path.isfile(f'{filename}.zip'):\n",
    "        os.remove(f'{filename}.zip')\n",
    "    if export_as_mp3:\n",
    "        os.chdir('separated/')\n",
    "        for i in stems:\n",
    "            wav_path = filename + i + '.wav'\n",
    "            mp3_path = filename + i + '.mp3'\n",
    "            get_ipython().system(f'ffmpeg -y -i \"{wav_path}\" -vn -ar 44100 -ac 2 -b:a 320k \"{mp3_path}\" -loglevel quiet')\n",
    "        os.chdir('../')\n",
    "        for move in stems:\n",
    "            shutil.move('separated/' + filename + move + '.mp3',filename)\n",
    "    else:\n",
    "        for move in stems:\n",
    "            shutil.move('separated/' + filename + move + '.wav',filename)\n",
    "    with hide_opt():\n",
    "        get_ipython().system(f'zip -r \"{filename}.zip\" \"{filename}\"')\n",
    "    shutil.rmtree(filename)\n",
    "    files.download(f'{filename}.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 512\n",
      "Model: HP2-4BAND-3090_4band_arch-500m_1\n",
      "Parameter: 4band_44100\n",
      "Aggressiveness: 0.3\n",
      "High end process: mirroring\n",
      "TTA: True\n",
      "Deep Extraction: False\n",
      "\n",
      "YouTube Link detected\n",
      "Downloading... done\n",
      "성시경(Sungsikyung)의 킬링보이스를 라이브로! - 너의 모든 순간, 좋을텐데, 넌 감동이었어, 희재, 두사람, 미소천사, 거리에서, 태양계, I Love Uㅣ딩고뮤직\n",
      "loading model... done\n",
      "stft of wave source... done\n",
      "100%|█████████████████████████████████████████| 448/448 [02:18<00:00,  3.22it/s]\n",
      "100%|█████████████████████████████████████████| 449/449 [02:14<00:00,  3.34it/s]\n",
      "inverse stft of Instruments... done\n",
      "inverse stft of Vocals... done\n",
      "Total time: 410.9s\n",
      "Notebook took: 414.6s\n"
     ]
    }
   ],
   "source": [
    "# ------------VSC REWRITE\n",
    "#type: ignore\n",
    "if os.path.isfile('main.py') == False:\n",
    "    if MountDrive:\n",
    "        os.chdir(mounting_path + '/VocalRemover5-COLAB_arch')\n",
    "    else:\n",
    "        os.chdir('/content/VocalRemover5-COLAB_arch')\n",
    "\n",
    "#parameter markdowns-----------------\n",
    "\n",
    "\n",
    "ScanSeparatedFolder = False #@param {type:\"boolean\"}\n",
    "#@markdown Convert all files in your tracks folder\n",
    "convertAll = False #@param {type:\"boolean\"}\n",
    "if convertAll:\n",
    "    convertAll = '--convert_all'\n",
    "else:\n",
    "    convertAll = ''\n",
    "#@markdown Model name (Upload your models in models folder)\n",
    "pretrained_model = \"HP2-4BAND-3090_4band_arch-500m_1.pth\" #@param [\"HighPrecison_4band_arch-124m_1.pth\",\"HighPrecison_4band_arch-124m_2.pth\",\"HP2-4BAND-3090_4band_arch-500m_1.pth\",\"HP2-4BAND-3090_4band_arch-500m_2.pth\",\"HP_4BAND_3090_arch-124m.pth\",\"LOFI_2band-1_arch-34m.pth\",\"LOFI_2band-2_arch-34m.pth\",\"NewLayer_4band_arch-130m_1.pth\",\"NewLayer_4band_arch-130m_2.pth\",\"NewLayer_4band_arch-130m_3.pth\",\"Vocal_HP_4BAND_3090_AGG_arch-124m.pth\",\"Vocal_HP_4BAND_3090_arch-124m.pth\",\"HP-KAROKEE-MSB2-3BAND-3090_arch-124m.pth\",\"HP2-MAIN-MSB2-3BAND-3090_arch-500m.pth\",\"HP-4BAND-V2_arch-124m.pth\",\"MGM-v5-2Band-32000-_arch-default-BETA1.pth\",\"MGM-v5-2Band-32000-_arch-default-BETA2.pth\",\"MGM-v5-3Band-44100-_arch-default-BETA.pth\",\"MGM-v5-4Band-44100-_arch-default-BETA1.pth\",\"MGM-v5-4Band-44100-_arch-default-BETA2.pth\",\"MGM-v5-KAROKEE-32000-_arch-default-BETA1.pth\",\"MGM-v5-KAROKEE-32000-_arch-default-BETA2-AGR.pth\",\"MGM-v5-MIDSIDE-44100-_arch-default-BETA1.pth\",\"MGM-v5-MIDSIDE-44100-_arch-default-BETA2.pth\",\"MGM-v5-Vocal_2Band-32000-_arch-default-BETA1.pth\",\"MGM-v5-Vocal_2Band-32000-_arch-default-BETA2.pth\",\"StackedMGM_1band_arch-default.pth\"]{allow-input: true}\n",
    "#@markdown ---\n",
    "#@markdown ### Arguments\n",
    "window_size =  512#@param {type:\"integer\"}\n",
    "if window_size < 320:\n",
    "    print('Warning: window_size lower than 320.')\n",
    "if window_size < 272:\n",
    "    window_size = 272\n",
    "#1band_sr32000_hl512.json  2band_44100_lofi.json  3band_44100_mid.json\n",
    "#1band_sr44100_hl512.json  2band_48000.json\t 4band_44100.json\n",
    "#2band_32000.json\t  3band_44100.json\t ensemble.json\n",
    "parameter = \"Auto detect\" #@param [\"Auto detect\",\"1band_sr32000_hl512.json\",\"1band_sr44100_hl512.json\", \"2band_32000.json\" , \"2band_44100_lofi.json\", \"2band_48000.json\", \"3band_44100.json\", \"3band_44100_mid.json\", \"3band_44100_msb2.json\", \"4band_44100.json\", \"4band_v2.json\"]\n",
    "parameter = \"modelparams/\" + parameter\n",
    "high_end_process = 'mirroring' #@param [\"none\",\"mirroring\", \"mirroring2\" , \"bypass\"]\n",
    "aggressiveness = '0.3' #@param {type:\"string\"}\n",
    "aggressiveness = float(aggressiveness)\n",
    "#@markdown Mute low volume vocals\n",
    "postprocess = False #@param {type: \"boolean\"}\n",
    "if postprocess:\n",
    "    threshold = 0.2 #@param {type:\"number\"}\n",
    "    min_range = 64 #?param {type:\"integer\"}\n",
    "    fade_size = 32 #?param {type:\"integer\"}\n",
    "    if min_range < fade_size * 2:\n",
    "        print('min_range must be greater than or equal fade_size * 2')\n",
    "        print('Using default instead. (except threshold)')\n",
    "        min_range = 32\n",
    "        fade_size = 64\n",
    "    postprocess = f\"-p -thres {threshold} -mrange {min_range} -fsize {fade_size}\"\n",
    "else:\n",
    "    postprocess = \"\"\n",
    "#@markdown ### Architecture\n",
    "nn_architecture = 'Auto detect' #@param [\"Auto detect\",\"default\", \"34 MB\", \"124 MB\", \"130 MB\", \"500 MB\"]\n",
    "if nn_architecture == '34 MB':\n",
    "    nn_architecture = '33966KB'\n",
    "elif nn_architecture == '124 MB':\n",
    "    nn_architecture = '123821KB'\n",
    "elif nn_architecture == '130 MB':\n",
    "    nn_architecture = '129605KB'\n",
    "elif nn_architecture == '500 MB':\n",
    "    nn_architecture = '537238KB'\n",
    "elif nn_architecture == 'default':\n",
    "    pass\n",
    "#@markdown ---\n",
    "#@markdown ### Checkboxes\n",
    "#@markdown Use GPU for faster conversion\n",
    "gpu = True #@param {type: \"boolean\"}\n",
    "if gpu == True:\n",
    "    gpu = 0\n",
    "else:\n",
    "    gpu = -1\n",
    "#@markdown Aggressively remove vocals from Instrumental\n",
    "deepExtraction = False #@param {type:\"boolean\"}\n",
    "if deepExtraction:\n",
    "    deepExtraction = \"-D\"\n",
    "else:\n",
    "    deepExtraction = \"\"\n",
    "#@markdown Flip Instruments and Vocals output (Only for Vocal Models)\n",
    "isVocal = False #@param {type:\"boolean\"}\n",
    "if isVocal:\n",
    "    isVocal = '--isVocal'\n",
    "else:\n",
    "    isVocal = ''\n",
    "#@markdown Hide warnings\n",
    "suppress = True #@param {type:\"boolean\"}\n",
    "if suppress:\n",
    "    suppress = '--suppress'\n",
    "else:\n",
    "    suppress = ''\n",
    "#@markdown Export spectogram image\n",
    "output_image = False #@param {type: \"boolean\"}\n",
    "if output_image:\n",
    "    output_image = \"-I\"\n",
    "else:\n",
    "    output_image = \"\"\n",
    "#@markdown perform Test Time Augmentation to improve the separation quality\n",
    "tta = True #@param {type: \"boolean\"}\n",
    "if tta:\n",
    "    tta = \"-t\"\n",
    "else:\n",
    "    tta = \"\"\n",
    "#@markdown Use custom arguments\n",
    "useCustomArguments = False #@param {type: \"boolean\"}\n",
    "CustomArguments = \"-h\" #@param {type:\"string\"}\n",
    "#@markdown Download files\n",
    "download = False #@param {type:\"boolean\"}\n",
    "export_as_mp3 = False #@param {type:\"boolean\"}\n",
    "#@markdown Use all model\n",
    "model_version = \"Don't use all model\" #@param [\"Don't use all model\",\"v5_new\", \"v5\", \"all\"]\n",
    "# {none,v5,v5_new,all}\n",
    "# automation\n",
    "if nn_architecture == 'Auto detect':\n",
    "    if 'arch-default' in pretrained_model:\n",
    "        nn_architecture = 'default'\n",
    "    elif 'arch-34m' in pretrained_model:\n",
    "        nn_architecture = '33966KB'\n",
    "    elif 'arch-124m' in pretrained_model:\n",
    "        nn_architecture = '123821KB'\n",
    "    elif 'arch-130m' in pretrained_model:\n",
    "        nn_architecture = '129605KB'\n",
    "    elif 'arch-500m' in pretrained_model:\n",
    "        nn_architecture = '537238KB'\n",
    "    else:\n",
    "        print('Error! autoDetect_arch')\n",
    "        print('Using 124 MB instead.')\n",
    "        nn_architecture = '123821KB'\n",
    "if parameter == 'modelparams/Auto detect':\n",
    "    if '4band' in pretrained_model.lower():\n",
    "        if 'v2' in pretrained_model.lower():\n",
    "            parameter = 'modelparams/4band_v2.json'\n",
    "        else:\n",
    "            parameter = 'modelparams/4band_44100.json'\n",
    "    elif '3band' in pretrained_model.lower():\n",
    "        if 'msb2' in pretrained_model.lower():\n",
    "            parameter = 'modelparams/3band_44100_msb2.json'\n",
    "        else:\n",
    "            parameter = 'modelparams/3band_44100.json'\n",
    "    elif 'midside' in pretrained_model.lower():\n",
    "        parameter = 'modelparams/3band_44100_mid.json'\n",
    "    elif '2band' in pretrained_model.lower():\n",
    "        if 'lofi' in pretrained_model.lower():\n",
    "            parameter = 'modelparams/2band_44100_lofi.json'\n",
    "        else:\n",
    "            parameter = 'modelparams/2band_48000.json'\n",
    "    else:\n",
    "        print('Parameter auto detect failed, using 1band instead.')\n",
    "        parameter = 'modelparams/1band_sr44100_hl512.json'\n",
    "if '34m' in pretrained_model or '124m' in pretrained_model or '130m' in pretrained_model or '500m' in pretrained_model:\n",
    "    pretrained_model = \"models/v5_new/\" + pretrained_model\n",
    "else:\n",
    "    pretrained_model = \"models/v5/\" + pretrained_model\n",
    "    if os.path.isfile(pretrained_model) == False:\n",
    "        print('========================================================')\n",
    "        print('                Error model not found.')\n",
    "        print('Custom models should be uploaded in \"models/v5/\" folder!')\n",
    "        print('========================================================')\n",
    "if 'https://' not in input:\n",
    "    if ScanSeparatedFolder:\n",
    "        if input in ''.join(glob.glob('separated/*')):\n",
    "            input = 'separated/' + input\n",
    "        else:\n",
    "            print('File not found in separated folder.')\n",
    "            input = 'tracks/' + input\n",
    "    else:\n",
    "        input = 'tracks/' + input\n",
    "elif 'https://' in input and ScanSeparatedFolder:\n",
    "    print('Skipping \"Separated\" folder scan since a link is given.')\n",
    "\n",
    "if model_version == \"Don't use all model\":\n",
    "    model_version = 'none'\n",
    "\n",
    "# --------------AI----------------\n",
    "start_time = time.time()\n",
    "#window_size,os.path.splitext(os.path.basename(pretrained_model)[0]),os.path.splitext(os.path.basename(parameter)[0],settings_tta = 'True' if tta else 'False'\n",
    "#settings_tta = 'True' if tta else 'False',os.path.splitext(os.path.basename(parameter)[0],os.path.splitext(os.path.basename(pretrained_model)[0]),window_size\n",
    "settings_tta = 'True' if tta else 'False'\n",
    "settings_deepExtraction = 'True' if deepExtraction else 'False'\n",
    "\n",
    "print('Window size: {}'.format(window_size))\n",
    "print('Model: {}'.format(os.path.splitext(os.path.basename(pretrained_model))[0]))\n",
    "print('Parameter: {}'.format(os.path.splitext(os.path.basename(parameter))[0]))\n",
    "print('Aggressiveness: {}'.format(aggressiveness))\n",
    "print('High end process: {}'.format(high_end_process))\n",
    "\n",
    "print('TTA: {}'.format(settings_tta))\n",
    "print('Deep Extraction: {}'.format(settings_deepExtraction))\n",
    "print()\n",
    "if useCustomArguments == False:\n",
    "    get_ipython().system(f'python3.8 main.py -i \"{input}\" {convertAll} --useAllModel \"{model_version}\" --model_params \"{parameter}\" -P \"{pretrained_model}\" -w {window_size} -H \"{high_end_process}\" --aggressiveness {aggressiveness} -n \"{nn_architecture}\" -g {gpu} {deepExtraction} {isVocal} {suppress} {output_image} {postprocess} {tta}')\n",
    "    if download and convertAll:\n",
    "        sys.exit(\"No no, this is not an error but downloading with convertAll is not yet possible. Please DON'T report this to me (Hv) or the server\")\n",
    "    if download:\n",
    "        dlFile(input,pretrained_model,isYouTube='https://' in input,export_as_mp3=export_as_mp3)\n",
    "if useCustomArguments:\n",
    "    get_ipython().system(f'python3.8 main.py {CustomArguments}')\n",
    "print('Notebook took: {0:.{1}f}s'.format(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Clone Repositories\n",
    "import os\n",
    "\n",
    "firsttry = True\n",
    "\n",
    "# READ ME BEFORE CHANGING THINGS\n",
    "# If you're attempting to replace the imports here with Applio-RVC, it will not work due to requirement discrepancies across the entire notebook.\n",
    "# I will not be porting this notebook to Applio due to the failure of the Applio team to provide backwards compatibility with the Crepe and Mangio-Crepe f0 feature format.\n",
    "# DO NOT ASK. IT WILL NOT HAPPEN.\n",
    "\n",
    "os.chdir('/content/')\n",
    "\n",
    "#if(os.path.exists(\"/content/Mangio-RVC-Fork\")):\n",
    "#  print(\"RVC already installed, skipping.\")\n",
    "#else:\n",
    "#  #Credit to miaaaa0a on the AI Hub Discord for (indirectly) suggesting this variant of Mangio RVC to me.\n",
    "#  !git clone -b pr-optimization --single-branch https://github.com/alexlnkp/Mangio-RVC-Tweaks.git\n",
    "#  #Rename to keep backwards compatibility with old variants of Disconnected\n",
    "#  os.rename(\"/content/Mangio-RVC-Tweaks\", \"/content/Mangio-RVC-Fork\")\n",
    "#  !git clone https://github.com/maxrmorrison/torchcrepe.git\n",
    "#  !mv torchcrepe/torchcrepe Mangio-RVC-Fork/\n",
    "#  !rm -rf torchcrepe  # Delete the torchcrepe repository folder\n",
    "\n",
    "os.chdir('/content/Mangio-RVC-Fork')\n",
    "now_dir = \"/content/Mangio-RVC-Fork\"\n",
    "os.makedirs(os.path.join(now_dir, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(now_dir, \"weights\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title GPU Check\n",
    "import torch\n",
    "\n",
    "ngpu = torch.cuda.device_count()\n",
    "gpu_infos = []\n",
    "mem = []\n",
    "if_gpu_ok = False\n",
    "\n",
    "if torch.cuda.is_available() or ngpu != 0:\n",
    "  for i in range(ngpu):\n",
    "    gpu_name = torch.cuda.get_device_name(i)\n",
    "    if any(\n",
    "        value in gpu_name.upper()\n",
    "        for value in [\"10\", \"16\", \"20\", \"30\", \"40\", \"A2\", \"A3\", \"A4\", \"P4\", \"A50\", \"500\", \"A60\", \"70\", \"80\", \"90\", \"M4\", \"T4\", \"TITAN\"]\n",
    "    ):\n",
    "      if_gpu_ok = True\n",
    "      print(\"Compatible GPU detected: %s\" % gpu_name)\n",
    "      gpu_infos.append(\"%s\\t%s\" % (i, gpu_name))\n",
    "      mem.append(int(torch.cuda.get_device_properties(i).total_memory / 1024 / 1024 / 1024 + 0.4))\n",
    "\n",
    "if if_gpu_ok and len(gpu_infos) > 0:\n",
    "  gpu_info = \"\\n\".join(gpu_infos)\n",
    "\n",
    "else:\n",
    "  raise Exception(\"No GPU detected; training cannot continue. Please change your runtime type to a GPU.\")\n",
    "gpus = \"-\".join(i[0] for i in gpu_infos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mount Drive\n",
    "os.makedirs('/content/rvcDisconnected', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup CSVDB\n",
    "#...Alright, you made your point.\n",
    "import csv\n",
    "\n",
    "if not os.path.isdir(\"csvdb/\"):\n",
    "  os.makedirs(\"csvdb\")\n",
    "  frmnt, stp = open(\"csvdb/formanting.csv\", \"w\", newline=\"\"), open(\"csvdb/stop.csv\", \"w\", newline=\"\")\n",
    "  csv_writer = csv.writer(frmnt, delimiter=\",\")\n",
    "  csv_writer.writerow([False, 1.0, 1.0])\n",
    "  csv_writer = csv.writer(stp, delimiter=\",\")\n",
    "  csv_writer.writerow([False])\n",
    "  frmnt.close()\n",
    "  stp.close()\n",
    "\n",
    "global DoFormant, Quefrency, Timbre\n",
    "DoFormant, Quefrency, Timbre = False, 1.0, 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
